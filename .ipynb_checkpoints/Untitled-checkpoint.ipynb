{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "4 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "8 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "16 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "32 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "64 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "128 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 \n",
      "256 ::: 0 25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 [2, 4, 8, 16, 32, 64, 128, 256]\n",
      "[ 0.86157867  1.32289644  1.25253654  0.60331238  0.77763153  0.61307573\n",
      "  0.81400574  1.11947213]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:107: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:13: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:25: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "'''\n",
    "    Returns a random unit vector, dim is the dimension of the vector. high sigma, better the randomness \n",
    "'''\n",
    "def random_unit_norm(dim,sigma = 100):\n",
    "    mean = np.zeros([dim])\n",
    "    cor  = sigma*np.identity(dim)\n",
    "    gaussian    = np.random.multivariate_normal(mean, cor)\n",
    "    unit_vector = gaussian/np.linalg.norm(gaussian)\n",
    "    return unit_vector\n",
    "\n",
    "'''\n",
    "    Return the eigen vector corresponding to the maximum eigen value\n",
    "'''\n",
    "def max_eigen_value(Array):\n",
    "#     Array = np.identity(Array.shape[0])\n",
    "#     Array[2][2] = 2\n",
    "    eig_val, eig_vec =   np.linalg.eigh(Array)\n",
    "    max_index = np.any( np.argmax(eig_val) )\n",
    "    return eig_vec[max_index]\n",
    "\n",
    "'''\n",
    "    Choice of w_i is chosen to be th maximum of the \n",
    "'''\n",
    "def optimal_w_choices(x,sigma,x_cor,k):\n",
    "    \n",
    "    dim = x.shape[0]\n",
    "    Y = np.zeros(k)\n",
    "    W = np.zeros([k,dim])\n",
    "    for i in range(k):\n",
    "        W_restricted = W[:i]\n",
    "        \n",
    "        #Calculating the new Correlatoin matrix\n",
    "        if i > 0:\n",
    "            Inv = np.linalg.inv( W_restricted.dot(x_cor).dot(W_restricted.T) + np.identity(i)*sigma*sigma)\n",
    "            New_cor = x_cor - x_cor.dot(W_restricted.T).dot( Inv ).dot(W_restricted.dot(x_cor.T))\n",
    "        else:\n",
    "            New_cor = x_cor\n",
    "            \n",
    "        # Search foe the best w_i\n",
    "        W[i] = max_eigen_value(New_cor)\n",
    "        Y[i] = W[i].dot(x) + np.random.normal()*sigma*sigma\n",
    "    \n",
    "    #Sanity check Estimating X by least square\n",
    "#     WT_W = W.T.dot(W)\n",
    "#     WT_Y = W.T.dot(Y)\n",
    "    Temp1 = W.dot(x_cor).dot(W.T) + np.identity(k)*sigma*sigma\n",
    "    X_estimate = x_cor.dot(W.T).dot( np.linalg.inv(Temp1) ).dot(Y)\n",
    "    \n",
    "    return np.linalg.norm(X_estimate-x)\n",
    "\n",
    "def random_w_choices(x,sigma,x_cor,k):\n",
    "    dim = x.shape[0]\n",
    "    Y_random = np.zeros(k)\n",
    "    Y_optimal = np.zeros(k)\n",
    "    W_random = np.zeros([k,dim])\n",
    "    W_optimal = np.zeros([k,dim])\n",
    "    for i in range(k):\n",
    "        #Picking w_i randomly\n",
    "        W_random[i] = random_unit_norm(dim, 1000) #Large value of sigma for improving the unformity\n",
    "        \n",
    "        #picking w_i optimally\n",
    "        W_restricted = W_optimal[:i]\n",
    "        #Calculating the new Correlatoin matrix\n",
    "        if i > 0:\n",
    "            Inv = np.linalg.inv( W_restricted.dot(x_cor).dot(W_restricted.T) + np.identity(i)*sigma*sigma)\n",
    "            New_cor = x_cor - x_cor.dot(W_restricted.T).dot( Inv ).dot(W_restricted.dot(x_cor.T))\n",
    "        else:\n",
    "            New_cor = x_cor        \n",
    "        # Search foe the best w_i\n",
    "        W_optimal[i] = max_eigen_value(New_cor)\n",
    "        \n",
    "        noise = np.random.normal()*sigma*sigma\n",
    "        Y_random[i] = W_random[i].dot(x) + noise\n",
    "        Y_optimal[i] = W_optimal[i].dot(x) + noise\n",
    "    \n",
    "    #Sanity check Estimating X by least square\n",
    "#     WT_W = W_random.T.dot(W_random)\n",
    "#     WT_Y = W_random.T.dot(Y_random)\n",
    "    #X_LS_est = np.linalg.inv(WT_W).dot(WT_Y)\n",
    "    \n",
    "    Temp1 = W_random.dot(x_cor).dot(W_random.T) + np.identity(k)*sigma*sigma\n",
    "    X_random_estimate = x_cor.dot(W_random.T).dot( np.linalg.inv(Temp1) ).dot(Y_random)\n",
    "    \n",
    "    Temp2 = W_optimal.dot(x_cor).dot(W_optimal.T) + np.identity(k)*sigma*sigma\n",
    "    X_optimal_estimate = x_cor.dot(W_optimal.T).dot( np.linalg.inv(Temp2) ).dot(Y_optimal)\n",
    "\n",
    "#     print \"Least squares : Error fraction\" , np.linalg.norm(X_LS_est-x)/np.linalg.norm(x)\n",
    "#     print \"Random : Error fraction\" , np.linalg.norm(X_estimate-x)/np.linalg.norm(x)\n",
    "    return np.linalg.norm(X_random_estimate-x) , np.linalg.norm(X_optimal_estimate-x) , \n",
    "\n",
    "def calc(x_cor,x_mean):\n",
    "        \n",
    "    dim = np.shape(x_cor)[0];\n",
    "    num_tests = 400;\n",
    "    sigma = 20;\n",
    "    K_vals = [2, 4, 8, 16,32,64,128,256,];\n",
    "    Random_error = np.zeros([len(K_vals)])\n",
    "    Optimal_error = np.zeros([len(K_vals)])\n",
    "#     TOptimal_error = np.zeros([len(K_vals)])\n",
    "    \n",
    "    x = np.random.multivariate_normal(x_mean, x_cor)\n",
    "    for j, k in enumerate( K_vals ):\n",
    "        print '\\n', k , \":::\",\n",
    "#         print Random_error\n",
    "#         print Optimal_error, \"\\n\"\n",
    "        #print TOptimal_error, \"\\n\"\n",
    "        for i in range(num_tests):\n",
    "            if i%25 == 0:\n",
    "                print i ,\n",
    "            R,O = random_w_choices(x, sigma, x_cor,k)\n",
    "            Random_error[j] = +R/num_tests\n",
    "            Optimal_error[j] = +O/num_tests\n",
    "            #TOptimal_error[j] = +optimal_w_choices(x, sigma, x_cor,k)/num_tests\n",
    "            \n",
    "#     print Random_error\n",
    "#     print Optimal_error\n",
    "    \n",
    "#     plt.semilogy(K_vals,Random_error, marker='o', lw=0.5, color=\"blue\", basey=2,alpha=1)\n",
    "#     plt.semilogy(K_vals,Optimal_error, marker='o', lw=0.5, color=\"red\", basey=2,alpha=1)\n",
    "    return (K_vals,Optimal_error/Random_error)\n",
    "\n",
    "def main():    \n",
    "    x_mean = np.zeros([10])\n",
    "    x_cor = np.array([\n",
    "     [5.279, 3.616, 3.651, 3.127, 3.877, 3.025, 2.48,  3.548, 3.019, 3.374],\n",
    "     [3.616, 3.837, 2.704, 2.119, 2.958, 2.787, 2.006, 2.898, 1.932, 2.068],\n",
    "     [3.651, 2.704, 3.546, 2.216, 2.681, 2.694, 1.882, 2.604, 2.006, 2.856],\n",
    "     [3.127, 2.119, 2.216, 2.401, 2.423, 2.101, 1.654, 2.535, 2.239, 2.112],\n",
    "     [3.877, 2.958, 2.681, 2.423, 3.72,  3.032, 2.47,  2.536, 2.517, 2.35 ],\n",
    "     [3.025, 2.787, 2.694, 2.101, 3.032, 3.513, 2.377, 2.843, 2.139, 2.491],\n",
    "     [2.48,  2.006, 1.882, 1.654, 2.47,  2.377, 1.893, 1.995, 1.9,   1.903],\n",
    "     [3.548, 2.898, 2.604, 2.535, 2.536, 2.843, 1.995, 4.154, 2.742, 2.569],\n",
    "     [3.019, 1.932, 2.006, 2.239, 2.517, 2.139, 1.9,  2.742, 3.174, 2.127],\n",
    "     [3.374, 2.068, 2.856, 2.112, 2.35,  2.491, 1.903, 2.569, 2.127, 3.165],\n",
    "    ]);\n",
    "     \n",
    "\n",
    "    x_iden = np.identity(10)\n",
    "    Xaxis, Yaxis = calc(x_iden,x_mean)\n",
    "    print Xaxis\n",
    "    print Yaxis\n",
    "\n",
    "#     plt.plot(Xaxis, Yaxis,marker='o', lw=0.5, color=\"red\",alpha=1)\n",
    "        \n",
    "#     red_patch =  mpatches.Patch(color='red', label='Indentity')\n",
    "#     blue_patch = mpatches.Patch(color='blue', label='Correlated')\n",
    "#     plt.legend(handles=[red_patch,blue_patch])\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
